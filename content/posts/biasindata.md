+++
title = 'Historical Bias In Data'
date = 2024-06-06T16:36:39+08:00
+++

Over the past ten years there have been numerous public scandals involving "Biased AI". These AI models have been shown to rely on biased data which occurs when system social prejudices are encoded into the data which underpins society. In this post we explore what bias is and whether it is always a bad thing for AI. 


## What is Bias? 

Bias is commly thought of as the tendency of reaching a decision which negatively impacts a certain group of people. When talking about AI, the term bias is used in conjunction with machine learning in many different contexts, and with many different meanings. 

## Is Bias Always Bad? 

Prior to any AI scandal, the term bias has an established historical meaning, within the technical community, that, at least on the surface, totally differs from how the term is used in typical news reporting.

In machine learning the term bias is used to describe the way in which algorithms learn to fit particular functions to data. 

This form of bias is crucial to the success of machine learning algorithms and is in stark contrast to the "AI bias" we see in the media. 


## Bias and Discrimination in AI

As AI grows in popularity, it has become increasingly ubuiquitous in traditonally human-led processes due to its efficiency and power. Alonside this AI boom, there have been an increasing number of documented "AI disasters" which have resulted in a group of individually unfairly impacted by an algorithm. 

## What Do We Want From Our AI? 
 
Current AI, and specifically machine learning, relies on data generated by humans to learn about the world. In this way, if humans continue to make biased decisions, so will the machines. 

Perhaps it is time to consider a new frontier of AI where move beyond a reliance on historical, biased data. Do we want our AI models to replicate human behaviour or can we do better?